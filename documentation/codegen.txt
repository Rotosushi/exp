// Copyright (C) 2024 Cade Weinberg
// 
// This file is part of exp.
// 
// exp is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
// 
// exp is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
// 
// You should have received a copy of the GNU General Public License
// along with exp.  If not, see <http://www.gnu.org/licenses/>.


"how does the backend generate target machine assembly?"

we need to select which target machine instructions implement the given IR.
we need to select the order in which these instructions are executed.
we need to select which registers the SSA locals are allocated.

then we have 
    - which instruction is being emitted?
    - what operands does it take as inputs?
    - what are it's outputs?
    - how does that affect the next instructions being emitted?
    - how does that affect the previous instructions that were emitted?

so, how do we map bytecode instructions to target machine instructions?

there isn't a direct mapping for the current iteration of bytecode instructions.
due to the three operand nature of the bytecode, and the two operand nature of x64.

essentially, the bytecode models the "side-effect" of producing a new value 
as the result of addition by storing it into a newly allocated local. 
(to preserve the SSA form.)
and the x64 instruction simply models the "side-effect" of producing a new value 
as the result of addition by storing it in the same register as one of the operands.
which has the side-effect of overwriting the original value of the operand.

which is similar to an accumulator. essentially the "+=" operation instead of 
the "+" operation. Now, what is nice about x64 is that you can keep one register 
as the "temporary" intermediate result as more and more additions are performed 
on a given SSA local. and given that all arithmetic operations are similarly 
"accumulator-style".
this analysis would carry if you mixed addition, subtraction, and multiplication.
where it breaks down is in the particulars.
for instance multiplication can only be considered as above if the "accumulator"
register is particularly %rax. and for division/modulus this only holds if the 
dividend in particular is the temporary value being threaded through the 
longer arithmetic expression.

what I hope for here is that if we devise a method which translates 
(A = B <op> C) bytecode into (B = B <op> C) x64, then we can apply that 
method to each arithmetic operation. and we only have to add constraints 
to allow for multiplication and division. we don't change the underlying 
method.


7 - "how does the register allocator use the IR to allocate variables?"

    So, from my current research into this, the "linear scan register allocation"
    seems to work nicely. It is less complex than graph coloring, and apparently 
    generates code which approaches the quality produced by graph coloring 
    [https://dl.acm.org/doi/10.1145/330249.330250]. 
    There are several algorithms which improve upon the initial algortihm as well.
    (one that I am particularly interested in is: 
    [https://arxiv.org/abs/2011.05608])

    the pseudo-code for linear scan register allocation:

    LinearScanRegisterAllocation
    active ← {}
    for each live interval i, in order of increasing start point do
        ExpireOldIntervals(i)
        if length(active) = R then
            SpillAtInterval(i)
        else
            register[i] ← a register removed from pool of free registers
            add i to active, sorted by increasing end point

    ExpireOldIntervals(i)
        for each interval j in active, in order of increasing end point do
            if endpoint[j] ≥ startpoint[i] then
                return 
            remove j from active
            add register[j] to pool of free registers

    SpillAtInterval(i)
        spill ← last interval in active
        if endpoint[spill] > endpoint[i] then
            register[i] ← register[spill]
            location[spill] ← new stack location
            remove spill from active
            add i to active, sorted by increasing end point
        else
            location[i] ← new stack location

    The algorithm relies on a set of "liveness ranges" or "live intervals"
    which are precomputed for each basic block. The live interval is 
    simply the interval that a given value is "alive." That is the 
    range over which a variable is accessible within the current scope.

    In order to allocate registers, this algorithm needs an enumeration 
    of all available registers on the target machine. 
    We also need to pre-allocate registers for incoming function arguments,
    and for outgoing function arguments, and for certain instructions. 
    (division, bit rotate, bit shift, etc.)

    and this leads naturally into:

7 - "how does the backend generate target machine assembly?"

    so, very broadly, it's walk each global symbol and 
    convert it into assembly. 

    specifically:
    
    -   global variables and constants can be converted 
        into global data in the assembly file, as long as the size is 
        known, space can be allocated within the assembly file. If an 
        initializer exists, then this can be added to the assembly 
        definition as well.

    -   functions are more complex. 
        broadly: convert each bytecode instruction into 
        an "equivalent" assembly instruction.

        There is often a 1-to-1 correspondence: 
        move -> mov 
        add -> add 
        etc...

        and when there isn't we can expand the produced 
        assembly to generate the semantics of the single bytecode 
        instruction.

        The harder question is how do we map the "infinite" set 
        of SSA local variables into a finite set of physical registers 
        and stack space?

        (note that 2^16 is not infinite, it's just larger than we 
         presume we will need for all but the longest functions.)

        first we have to compute the liveness intervals for all 
        locals within the function. Then the register allocator 
        uses that data to allocate locals to registers.
        Then the instruction selector uses the register mapping 
        to map bytecode instructions over SSA locals to assembly 
        instructions over registers and stack space.



