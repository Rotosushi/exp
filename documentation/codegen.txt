// Copyright (C) 2024 Cade Weinberg
// 
// This file is part of exp.
// 
// exp is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
// 
// exp is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
// 
// You should have received a copy of the GNU General Public License
// along with exp.  If not, see <http://www.gnu.org/licenses/>.

so, when considering emitting assembly code which can map to 
all of the constructions available within the langauge (that is,
implement the semantics of the language in assembly). 
I notice that there are a few major language elements that are 
necessary to represent.

-) globals
-) functions 
-) locals
-) expressions

obviously the above list is modulo types, and types are integral to 
how each of those things are expressed. 
and this discussion is also specific to what the target is,
 linux/windows/mac/etc.. and what the output format is 
 elf/coff/etc.. and what assembler is being targeted 
 gas/nasm/masm/fasm/etc...

so, for the sake of moving forward I am picking x86-64 
(my native arch), Linux (Ubuntu if that ends up mattering,
but I think what matters is system V abi),
elf64 object files, using gas (/usr/bin/as)


so, first we need to think about layout of the assembly file,
and thus the layout of the object file to be linked.

globals:
global constants (with or without an initializer) 
  can be placed into the .text section

global variables can be placed into the .data section 
global variables without an initializer can be placed into the .bss section 
global variables with an explicit zero initializer can be placed into 
  the .bss section as well

functions:
functions are placed into the .text section

locals:
locals are allocated into registers, or allocated onto the stack

expressions:
expressions are translated into code within functions,
  and thus go into the .text section 


then we need to consider how we initialize the different types 
of variables and constants.
(functions and expressions are not "initialized" per-say,
given that they are always constant in the assembly file.)

global variables are initialized when they are declared in the file.
Int types use .long 
Bool types use .byte 
Nil types use .byte

so, we need a function which emits global variables and global constants.
this means we need to keep track of global variables and global constants.
then we can and loop through our list of all globals and emit each.

local variables are stored in registers and on the stack.
we need a function which can allocate a variabler or constant into 
a register if possible or allocates the variable or constant onto the 
stack. 
then we can loop through the list of locals, when emitting a function,
and emit each local variable.

to emit an expression we have to keep track of where local variables and 
global variables are emitted in order to use their values within 
instructions in the expression. as well as needing mappings from operations 
to instructions. (such as '+' mapping to an addx instruction.)

in order to emit a function we simply have to emit the function prefix,
then emit all of the local variables, then emit each expression in the 
function, then emit the function postfix.


obviously there are a ton of details that this glosses over, 
but I think the gist is correct.
essentially define a function which maps each language construct to 
assembly. then loop over all of the in memory representation of the 
source code, and call these functions in order to emit the assembly 
representation of the source code.
all that is left after that is to invoke /usr/bin/as to produce an elf 
object file. then /usr/bin/ld to produce an executable.

emitting assembly looks like writing strings into a buffer.

in order to loop over language constructs, we must have an in memory 
representation of said language constructs. The classical choice is 
the abstract syntax tree. however that choice leads to performance 
degradation as the language as a whole grows in complexity.

another classical choice is the virtual machine. this choice has 
performance considerations as well, though it is far faster than 
chasing down pointers in an AST, and it is just as flexible.
as many interpreters are based in virtual machines. To my knowledge 
the only thing faster is running code directly on the cpu.

however, I am writing a compiler, trying to generate code that runs 
directly on the cpu. So this is "placing the cart before the horse" 
as it were. 

one step up from machine code is JIT, that is compile the source code
to machine code and run that. as opposed to running code within a VM.
this, again solves the problem of "generating machine code" with the 
solution of "generate machine code". which is again putting the cart 
before the horse.

thus, generating machine code directly from virtual machine instructions.

the only thing faster I think, would be to have the parser generate 
machine code directly. The question arises, how do you typecheck 
the emitted code? How do you account for types within expressions 
at all?

The classical approach has the parser create invalid expressions.
These expressions are then typechecked, and only when both steps 
have completed do we attempt to emit code for the expression.

This is in some sense, a multi pass compiler design. 
first we parse the source code, creating some form of
intermediate representation (IR. could be an AST or a byte array or etc..).
next we check that the IR is correct. (not adding bools to ints 
or calling a function with the wrong arguments etc...
this is what I have been calling Typechecking, though it is 
fair to check for errors that are not related to types as well.)
then we translate the IR into assembly. (this is what I have been calling 
the code generation step.)
then we assemble and link into the final executable.

The issue with having the parser emit machine code directly is that 
there is now the requirement that the parser produces correct 
"intermediate representation" even though there is no IR at all.
that is, what used to take two passes has been unified into a one pass.

the issue becomes, it is allowed by the grammar recognized by the parser 
to form operations on types which are not supported by those types.
such as addition on boolean types. (or in the future, addition on 
structure types.)




