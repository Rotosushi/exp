
/-----------------------------------------------------------------------------

After modifying the parser unit_tests to parse all of the resources in the 
test resources file I noticed that the difference between the runtimes of 
the "parser all resources test" and the "compile all test resources and test the 
exit code of the emitted programs" is really large. 

parse all resources: ~3ms
test all resources: ~345ms

(in a release build)

The relative change is 
((345 - 3) / 3) * 100 = 11,400

which means it takes 11,400% more time to complete.

now, test all resources does a lot more work. first it has to compile the 
program (which is inclusive of parsing the resource),
then run the assembler, then the linker. My thinking is that most 
of the added time is coming from the fact that we fork/exec the compiler,
the assembler, the linker, and the final executable. Which is 4 OS context switches,
plus the runtimes of each of those programs. 

the main way to mitigate this would be to embed an assembler and a linker into 
the compiler. Then we only have to pay the cost of interfacing with the filesystem.
which can be further reduced by pooling those resources, or never generating intermediate 
files at all. However the usage of intermediate files allows for compilation and assembly 
to occur in parallel as we compile a large project composed of many source files. Which 
seems like a potential speed-up over forcing single threaded compilation, even when considering 
paying the cost of a fork/exec.

it feels worth mentioning that projects like LLVM do embed an x86 assembler directly into the compiler.
(#TODO remember the source that I heard this from.) Precisely because it represents a major speedup.
(Think about it, with an embedded assembler,
 instead of x86 IR -> x86 ASM -> x86 OBJ -> x86 EXE/LIB,
 you can go x86 IR -> x86 OBJ -> x86 EXE/LIB.
 with an embedded linker as well,
 you can go x86 IR -> x86 EXE/LIB.
 though with the caveat that you have to use Thread instead of Process Parellism, 
 meaning the runtime size of your program must include the full size of the emitted 
 EXE/LIB. If you have a buffer per intermediate OBJ, can you modify them in-place?
 )

There are a few projects which could be used for this, without requiring something 
bespoke. 


(zydis)[https://github.com/zyantific/zydis]:
a fully featured x86-64 (and x86-32) assembler/dissassembler, in C, with no other deps. very nice!
the only information it does not include per-instruction is the CPU specific timing, and resource 
utilization, so it cannot be used as-is to do cost-analysis or resource-utilization-analysis.

(mold)[https://github.com/rui314/mold]:
a fully featured ELF linker, in C++. which is very fast. C++ is easier to integrate than most other languages 
however, it would still a challenge.

I am not convinced that this issue is large enough to warrant work, given the pressing nature of all of 
the other deficiencies in the compiler. However it still feels worth mentioning.


/-----------------------------------------------------------------------------

there is at least one use of goto: that is not made manifest in the
c programming language structures. (a'la structured programming, not structs)
and that is breaking out of a loop or switch one level up.
we could have a numbered, or a labeled break statement. where we introduce
labels for scope introduction constructs and allow a break statement to
jump out of that level of nesting. or we assign an implicit number to each 
level of nesting starting at 0, and going -1, -2, -3, ...
for each scope above the one we are at; that one being 0.
or just simply break; with no number.

This is however, beside a conversation of how hard it is to reason about
nested switch statements in and of themselves. and how large that code
becomes. This sounds like something a compiler optimization might be
able to come in and reason about that? but when, and why?
usually it's because of the structure of the logic, we know that we
need to return up and out.
the thing is, usually if you want that you also want to simply return out
of the function in the first place. at least if it's the error path we
are talking about.


/-------------------------------------------------------------------------------

What if:
when you return multiple types out of a function with an implied return type, those
multiple types are placed into a product type. Thus the function is primed to be pattern
matched over.

This is seemingly a good idea. we use product types wherever we have multiple kinds of types
to be returned. The only thing about C is that you explicitly create a tag, and use an
union type, and explicitly call out that you are switching over the tag. and you
have to roll the if statements or further switches inside the case to further
disambiguate the state of your enum object/struct/data/bits explicitly,
whereas pattern matching does all of the same with less keystrokes.

C++ has std::variant. rust has built-in enums. haskell has sum types

but these are all explicit types created by the user and named.

so, for the same reasons you might choose a tuple over a struct,
or a lambda over a function,
you could have an implicit enum type created by a function. 
from a certain perspective, the function becomes the declaration 
syntax of the enum type.
(or product type, if you will)

all it really does semantically is save on keystrokes.
because you can always promote the type to an explicit
typedef, and have the same semantics. which is what C has
already.

/--------------------------------------------------------------------------------

If we consider a struct to be a series of data members of any concrete type.
(first order kind? the * type) along with a series of functions with type * -> *

then a program in-and-of-itself is as a struct. or class if you will.
its functions are known, and it's available types are to. 
We use a "well-known address" to start up each program. (it's called "main")

tuples allow for multiple arguments and multiple return, as a sum type. (and)
"the type is all of these alternatives, at any given moment in time"

implicit enums also allow for multiple return, as a product type. (xor)
"the type is one of these alternatives, at any given moment in time"

you know "or" doesn't have a well known type, but semantically I
would imagine it as a tuple where each member was implicitly an optional type.
"the type is zero or more of these alternatives, at any given moment in time"
bitmask types work like this. an "or" type could have the same layout as a tuple, 
plus a comptime length bitmask of "presence" of any given member. so for a single element,
its equivalent to the option<T> type present in many languages. It can be stored using the size 
of the equivalent struct plus a byte, but since it's the compiler, that byte, or bytes,
can be placed in, or split across, any padding of the struct.

functions in the most general sense have the type * -> *, which is roughly equivalent to 
the C type: <void * (*)(void *)> as far as I understand it.
thats what the type * -> * is/means, semantically. (or maybe more accurately in C++ <T (*)(U)>)
it's just that the C compiler lets you implicitly pass a tuple of arguments instead of 
always forcing you to wrap them all into a type. and return a scalar value out via a register 
instead of by pointer. Composite types too large to fit within a register are passed out via 
a hidden reference, (which is what i am referring to with the "void *" return type above)
However the return type is not symmetric with the "tuple" of arguments, as it must be a single
type. thus you have to use structs to return multiple values out of a function.
and C++ inherits this syntax. It is convienent to return out a tuple, which allows for something 
that looks and feels sytactically like multiple return values, however under the hood can 
be handled exactly the same as returning a uniquely named structure type.

This is where the implicit enum type comes from, we can simply generalize this idea further, and 
allow for something that looks like returning multiple Types out of the function, but in reality 
acts just like an uniquely named enum type. (product type, union type, whatever you want to call it).


/--------------------------------------------------------------------------------

