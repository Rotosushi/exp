// Copyright (C) 2024 Cade Weinberg
// 
// This file is part of exp.
// 
// exp is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
// 
// exp is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
// 
// You should have received a copy of the GNU General Public License
// along with exp.  If not, see <https://www.gnu.org/licenses/>.

The current plan is to extend the compilers functionality.
reaching for a stable and useful base language. which is then 
extended via a standard library.

the current subgoal here is adding support for string-literals.

to my eyes, string-literals are really string-views into global constants.
and string-views are implemented as a pair of an i64 and a character pointer.
and pairs can be generalized to tuples.

characters leads into a discussion on utf-8 strings.
and utf-8 string processing.
string-literals are then used to implement the import mechanism.
which leads directly to modules and namespaces.
string-literals are used to implement error messages.
and tuples are used alongside unions to implement a result type,
which is the basis for error handling in the language.
then we add a more robust suite of scalar types, alongside more binary 
and unary operators. which leads to literals of different types.
which leads directly into casting.
and casting leads to type reflection (and uses the error handling mechanism).
and binary and unary operators touch on function overloading and function 
templates when we consider the same function, i.e. '+', being used on multiple 
types, integer types and floating point types, while this can be handled by the 
core langauge fundamentally this is function overloading. in the same way that 
the tuple type is fundamentally a template type.
pointers leads to dynamic memory allocation.


so, to start, we are adding support for tuples.
now that we have those what is the next most basic thing?
well, it's a toss up between utf-8 strings (and thus utf-8 characters),
pointers, and global constants other than functions.

okay, so I think global constants other than functions is the next thing I want to 
work on. because that is essentially "filling out" the existing language.
We have global constants already except only functions. so supporting global constant 
scalars and composite values just adds functionality where one would expect it.
and it can be noted that the machinery needed to declare global constants is going to 
be the same that is used to embed string-literals into the binary.


---------------------------------------------------------------------------------

regarding the speed of the compiler, I think that fundamentally the running time 
of the compiler should be O(N) where N is the size of the input source.
that is, how fast the compilation goes is proportional to the size of the 
input. This only seems to be complicated if the compiler must do complex analysis 
or optimizations that are themselves O(N^M) or similar.

Think about it:

while (haven't parsed all source)
    parse source into IR

...

while (haven't typechecked all IR)
    typecheck IR

...

while (haven't translated all IR)
    translate IR into ASM

...

while (haven't emitted all ASM)
    emit ASM

unless one of those steps needs to itself loop through
everything else, the running speed of the step is O(N).

global optimizations can get in the way of this.

imagine an optimization which to operate properly in it's 
local space, must consider the state of the whole program.
To consider the state of the whole program we have to loop 
through all of that state.
This would combine to be something like

while (haven't applied all optimizations)
    apply optimizations
    ...
    while (haven't considered all global state)
        consider global state.

where the "..." probably refers to several stack frames and 
whatever else.

this becomes O(N^2).

----------------------------------------------------------------------------------

regarding optimization:

it seems like the process of optimization is about adding, removing, or 
rewriting the input code to be more efficient in some particular way.

This means that fundamentally we have to support adding instructions 
into the bytecode anywhere in the array. 
(this is supported by the bytecode_insert function already) 
    (- we can note that if we are adding instructions, 
we dont have to do anything special, and the existing code will
not break.)


removing bytecode from the array
    if we remove a local which is referenced by later code
    we have to replace that incoming value with something, 
    which implies

that we also need to modify existing instructions within the array.

we also need to compute when to do the optimizations.
this means reading the bytecode and computing various properties 
(I can imagine, "how much bigger does the executable get when I 
inline this function everywhere?"
how many instruction cycles do we expect this procedure to take?
how filled will the pipeline be? 
How filled is the ALU? FPU?
how much memory will this operation cost me?
how much time?

can we get numbers?
orders of magnitude?
greater than less than?

how long did it take to compile said function file project library?
how much memory did that take?
where are the hotspots in spacetime?
can I get a heat map?
4 dimensional?


)






